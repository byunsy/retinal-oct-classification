{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Retinal_OCT_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNSrB2ZEQKHmk5z9lT9q8gG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byunsy/retinal-oct-classification/blob/main/Retinal_OCT_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmMl-DekFade"
      },
      "source": [
        "# Retinal OCT (Optical Coherence Topography) Classification\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR57bW877UCK"
      },
      "source": [
        "## 01. Import Necessary Packages\n",
        "We first need to import several packages. We will be using TensorFlow and Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDk0bOAj7BAq"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohx5nWiL7TH9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUOWGPWdDfch"
      },
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FMgSW67-OvW"
      },
      "source": [
        "## 02. Attain Dataset from Kaggle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Z9aE1JUJga"
      },
      "source": [
        "Firstly, pip install kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lApenIGGHfi_"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa2Y1tRfUWBi"
      },
      "source": [
        "Also import google.colab to upload the kaggle.json file which can be downloaded manually from your kaggle account."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwUwHXC5Hln9"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtEKqsotUmvi"
      },
      "source": [
        "Make a new directory and copy the kaggle.json file to that directory. This is required to download datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5fd83e1H1GA"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxETWAoWUxSg"
      },
      "source": [
        "Make some changes to the permission settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0xugUklH5pL"
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulaij36lU06E"
      },
      "source": [
        "Download the desired datasets. It is easy if you go to the dataset, and click the additional setting (three dots) and \"copy API command\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiOtGXkEKGjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279aeafc-e47d-4c2d-9eb4-b5a6cfed970f"
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/kermany2018"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading kermany2018.zip to /content\n",
            "100% 10.8G/10.8G [04:19<00:00, 35.9MB/s]\n",
            "100% 10.8G/10.8G [04:19<00:00, 44.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIQNBDpGVMqA"
      },
      "source": [
        "Now unzip the downloaded zip folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI2IiAuRQsIF"
      },
      "source": [
        "!unzip /content/kermany2018.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10wg4_RP46UX"
      },
      "source": [
        "Delete some unnecessary folders and files from unzipped directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ZewlNo4leg"
      },
      "source": [
        "!rm -r /content/oct2017/"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvyrMsEmRk1y"
      },
      "source": [
        "## 03. Understanding the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elZdykM2xM8a"
      },
      "source": [
        "Firstly, create directory paths for the base directory and its main subdirectories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg6dyZrNwMSq"
      },
      "source": [
        "# Create directory paths\n",
        "base_dir = os.path.join(os.path.dirname('/content/kermany2018.zip'), 'OCT2017')\n",
        "\n",
        "test_dir  = os.path.join(base_dir, 'test')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir   = os.path.join(base_dir, 'val')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTtZ_2yu_K7M"
      },
      "source": [
        "Now, let's learn more about the number of images in each directory.\n",
        "\n",
        "**Note that the unzipped directory has a space at the end of OCT2017. Be sure to remove it before proceeding to the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isYX7Dqdg5UR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c91641-323c-4f70-b2fa-6c0fa9460775"
      },
      "source": [
        "# Number of images\n",
        "num_ts_norm   = len(os.listdir(os.path.join(test_dir, 'NORMAL')))\n",
        "num_ts_cnv    = len(os.listdir(os.path.join(test_dir, 'CNV')))\n",
        "num_ts_dme    = len(os.listdir(os.path.join(test_dir, 'DME')))\n",
        "num_ts_drusen = len(os.listdir(os.path.join(test_dir, 'DRUSEN')))\n",
        "num_ts = num_ts_norm + num_ts_cnv + num_ts_dme + num_ts_drusen\n",
        "\n",
        "num_tr_norm   = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\n",
        "num_tr_cnv    = len(os.listdir(os.path.join(train_dir, 'CNV')))\n",
        "num_tr_dme    = len(os.listdir(os.path.join(train_dir, 'DME')))\n",
        "num_tr_drusen = len(os.listdir(os.path.join(train_dir, 'DRUSEN')))\n",
        "num_tr = num_tr_norm + num_tr_cnv + num_tr_dme + num_tr_drusen\n",
        "\n",
        "num_vl_norm   = len(os.listdir(os.path.join(val_dir, 'NORMAL')))\n",
        "num_vl_cnv    = len(os.listdir(os.path.join(val_dir, 'CNV')))\n",
        "num_vl_dme    = len(os.listdir(os.path.join(val_dir, 'DME')))\n",
        "num_vl_drusen = len(os.listdir(os.path.join(val_dir, 'DRUSEN')))\n",
        "num_vl = num_vl_norm + num_vl_cnv + num_vl_dme + num_vl_drusen\n",
        "\n",
        "# Display number of images in each directory\n",
        "print(\"TOTAL NUMBER OF TEST IMAGES:\", num_ts)\n",
        "print(\"Number of NORMAL - TEST :\", num_ts_norm)\n",
        "print(\"Number of CNV    - TEST :\", num_ts_cnv)\n",
        "print(\"Number of DME    - TEST :\", num_ts_dme)\n",
        "print(\"Number of DRUSEN - TEST :\", num_ts_drusen, \"\\n\")\n",
        "\n",
        "print(\"TOTAL NUMBER OF TRAIN IMAGES:\", num_tr)\n",
        "print(\"Number of NORMAL - TRAIN :\", num_tr_norm)\n",
        "print(\"Number of CNV    - TRAIN :\", num_tr_cnv)\n",
        "print(\"Number of DME    - TRAIN :\", num_tr_dme)\n",
        "print(\"Number of DRUSEN - TRAIN :\", num_tr_drusen, \"\\n\")\n",
        "\n",
        "print(\"TOTAL NUMBER OF VALIDATION IMAGES:\", num_vl)\n",
        "print(\"Number of NORMAL - VALIDATION :\", num_vl_norm)\n",
        "print(\"Number of CNV    - VALIDATION :\", num_vl_cnv)\n",
        "print(\"Number of DME    - VALIDATION :\", num_vl_dme)\n",
        "print(\"Number of DRUSEN - VALIDATION :\", num_vl_drusen, \"\\n\")\n",
        "\n",
        "print(\"-\"*50)\n",
        "print(\"NORMAL :\", num_ts_norm + num_tr_norm + num_vl_norm)\n",
        "print(\"CNV    :\", num_ts_cnv + num_tr_cnv + num_vl_cnv)\n",
        "print(\"DME    :\", num_ts_dme + num_tr_dme + num_vl_dme)\n",
        "print(\"DRUSEN :\", num_ts_drusen + num_tr_drusen + num_vl_drusen)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOTAL NUMBER OF TEST IMAGES: 968\n",
            "Number of NORMAL - TEST : 242\n",
            "Number of CNV    - TEST : 242\n",
            "Number of DME    - TEST : 242\n",
            "Number of DRUSEN - TEST : 242 \n",
            "\n",
            "TOTAL NUMBER OF TRAIN IMAGES: 83484\n",
            "Number of NORMAL - TRAIN : 26315\n",
            "Number of CNV    - TRAIN : 37205\n",
            "Number of DME    - TRAIN : 11348\n",
            "Number of DRUSEN - TRAIN : 8616 \n",
            "\n",
            "TOTAL NUMBER OF VALIDATION IMAGES: 32\n",
            "Number of NORMAL - VALIDATION : 8\n",
            "Number of CNV    - VALIDATION : 8\n",
            "Number of DME    - VALIDATION : 8\n",
            "Number of DRUSEN - VALIDATION : 8 \n",
            "\n",
            "--------------------------------------------------\n",
            "NORMAL : 26565\n",
            "CNV    : 37455\n",
            "DME    : 11598\n",
            "DRUSEN : 8866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwbZwUnSGM7x"
      },
      "source": [
        "Notice that we only have **32** validation images and **968** test images whereas we have over **83,484** training images. To get a less extreme division in the dataset, we will first append the three sets together and then randomly split them into testing, training and validation sets with 80:10:10 ratio. \n",
        "\n",
        "It is important to note that we also have some imbalance in the number of images for different categories (NORMAL, CNV, DME, DRUSEN). To handle this issue, we will create class weights which we will later use in the model training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvp5yuWH9TSt"
      },
      "source": [
        "## 04. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwNeRiU1E2Tf"
      },
      "source": [
        "# Move the images to corresponding directories (from val to train)\n",
        "!mv /content/OCT2017/val/NORMAL/* /content/OCT2017/train/NORMAL/\n",
        "!mv /content/OCT2017/val/CNV/* /content/OCT2017/train/CNV/\n",
        "!mv /content/OCT2017/val/DME/* /content/OCT2017/train/DME/\n",
        "!mv /content/OCT2017/val/DRUSEN/* /content/OCT2017/train/DRUSEN/\n",
        "\n",
        "# Move the images to corresponding directories (from test to train)\n",
        "!mv /content/OCT2017/test/NORMAL/* /content/OCT2017/train/NORMAL/\n",
        "!mv /content/OCT2017/test/CNV/* /content/OCT2017/train/CNV/\n",
        "!mv /content/OCT2017/test/DME/* /content/OCT2017/train/DME/\n",
        "!mv /content/OCT2017/test/DRUSEN/* /content/OCT2017/train/DRUSEN/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDRhLTaX9Z0I"
      },
      "source": [
        "Check if the files have moved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "350HSa7BHv91"
      },
      "source": [
        "# Number of images\n",
        "num_ts_norm   = len(os.listdir(os.path.join(test_dir, 'NORMAL')))\n",
        "num_ts_cnv    = len(os.listdir(os.path.join(test_dir, 'CNV')))\n",
        "num_ts_dme    = len(os.listdir(os.path.join(test_dir, 'DME')))\n",
        "num_ts_drusen = len(os.listdir(os.path.join(test_dir, 'DRUSEN')))\n",
        "num_ts = num_ts_norm + num_ts_cnv + num_ts_dme + num_ts_drusen\n",
        "\n",
        "num_tr_norm   = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\n",
        "num_tr_cnv    = len(os.listdir(os.path.join(train_dir, 'CNV')))\n",
        "num_tr_dme    = len(os.listdir(os.path.join(train_dir, 'DME')))\n",
        "num_tr_drusen = len(os.listdir(os.path.join(train_dir, 'DRUSEN')))\n",
        "num_tr = num_tr_norm + num_tr_cnv + num_tr_dme + num_tr_drusen\n",
        "\n",
        "num_vl_norm   = len(os.listdir(os.path.join(val_dir, 'NORMAL')))\n",
        "num_vl_cnv    = len(os.listdir(os.path.join(val_dir, 'CNV')))\n",
        "num_vl_dme    = len(os.listdir(os.path.join(val_dir, 'DME')))\n",
        "num_vl_drusen = len(os.listdir(os.path.join(val_dir, 'DRUSEN')))\n",
        "num_vl = num_vl_norm + num_vl_cnv + num_vl_dme + num_vl_drusen\n",
        "\n",
        "# Display number of images in each directory\n",
        "print(\"TOTAL NUMBER OF TEST IMAGES:\", num_ts)\n",
        "print(\"Number of NORMAL - TEST :\", num_ts_norm)\n",
        "print(\"Number of CNV    - TEST :\", num_ts_cnv)\n",
        "print(\"Number of DME    - TEST :\", num_ts_dme)\n",
        "print(\"Number of DRUSEN - TEST :\", num_ts_drusen, \"\\n\")\n",
        "\n",
        "print(\"TOTAL NUMBER OF TRAIN IMAGES:\", num_tr)\n",
        "print(\"Number of NORMAL - TRAIN :\", num_tr_norm)\n",
        "print(\"Number of CNV    - TRAIN :\", num_tr_cnv)\n",
        "print(\"Number of DME    - TRAIN :\", num_tr_dme)\n",
        "print(\"Number of DRUSEN - TRAIN :\", num_tr_drusen, \"\\n\")\n",
        "\n",
        "print(\"TOTAL NUMBER OF VALIDATION IMAGES:\", num_vl)\n",
        "print(\"Number of NORMAL - VALIDATION :\", num_vl_norm)\n",
        "print(\"Number of CNV    - VALIDATION :\", num_vl_cnv)\n",
        "print(\"Number of DME    - VALIDATION :\", num_vl_dme)\n",
        "print(\"Number of DRUSEN - VALIDATION :\", num_vl_drusen, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHJP7nHZZHWk"
      },
      "source": [
        "We can see that we have successfully moved all the validation images to the training directory. We will now properly split the dataset using train_test_split() from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4KDD2JWO3LM"
      },
      "source": [
        "# Get a list of all the filenames in the train directory\n",
        "files = glob.glob(\"/content/chest_xray/train/*/*\")\n",
        "\n",
        "# Randomly shuffle and split the files into two sets (lists) in 80:20 ratio\n",
        "train_files, val_files = train_test_split(files, test_size=0.2)\n",
        "\n",
        "# Number of training and validation images\n",
        "NUM_TRAIN = len(train_files)\n",
        "NUM_VALIDATION = len(val_files)\n",
        "\n",
        "print(\"TRAIN     :\", NUM_TRAIN)\n",
        "print(\"VALIDATION:\", NUM_VALIDATION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLN2cQKW9t1G"
      },
      "source": [
        "We now have a proper split between training and validation sets. \n",
        "\n",
        "Let's create a function to identify the label of an image and count the number of **NORMAL** and **PNEUMONIA** images in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN96S30Uug8p"
      },
      "source": [
        "# Parses the filename and determines whether it is in normal or pneumonia class\n",
        "# Returns True or 1 if it is PNEU. False or 0 if it is NORM (not PNEU)\n",
        "def get_label(filename):\n",
        "  label = filename.split(os.path.sep)[-2]\n",
        "  return label == 'PNEUMONIA'\n",
        "\n",
        "# Counter\n",
        "NUM_NORM = 0\n",
        "NUM_PNEU = 0\n",
        "\n",
        "# Iterate through each file and increment accordingly\n",
        "for file in train_files:\n",
        "  if get_label(file):\n",
        "    NUM_PNEU += 1\n",
        "  else:\n",
        "    NUM_NORM += 1\n",
        "\n",
        "print(\"NORMAL    in TRAINING:\", NUM_NORM)\n",
        "print(\"PNEUMONIA in TRAINING:\", NUM_PNEU)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E2_tL4yHvY-"
      },
      "source": [
        "Organize these newly split training and validation sets in correct directories. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7EcgHWpadJY"
      },
      "source": [
        "# For each file, determine its label(NORM or PNEU) and move it to its\n",
        "# corresponding directory. \n",
        "# If it is already in the correct directory, then do nothing (pass).\n",
        "\n",
        "for file in train_files:\n",
        "  try:\n",
        "    if get_label(file):\n",
        "      shutil.move(file, os.path.join(train_dir, 'PNEUMONIA'))\n",
        "    else:\n",
        "      shutil.move(file, os.path.join(train_dir, 'NORMAL'))\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "for file in val_files:\n",
        "  try:\n",
        "    if get_label(file):\n",
        "      shutil.move(file, os.path.join(val_dir, 'PNEUMONIA'))\n",
        "    else:\n",
        "      shutil.move(file, os.path.join(val_dir, 'NORMAL'))\n",
        "  except: \n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y261sFQuQU-"
      },
      "source": [
        "Check if we have done so successfully and accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyDoSEwLKpYO"
      },
      "source": [
        "# Number of images\n",
        "num_tr_norm = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\n",
        "num_tr_pneu = len(os.listdir(os.path.join(train_dir, 'PNEUMONIA')))\n",
        "num_tr = num_tr_norm + num_tr_pneu\n",
        "\n",
        "num_vl_norm = len(os.listdir(os.path.join(val_dir, 'NORMAL')))\n",
        "num_vl_pneu = len(os.listdir(os.path.join(val_dir, 'PNEUMONIA')))\n",
        "num_vl = num_vl_norm + num_vl_pneu\n",
        "\n",
        "# Display\n",
        "print(\"TOTAL NUMBER OF TRAIN IMAGES:\", num_tr)\n",
        "print(\"Number of NORMAL    - TRAIN :\", num_tr_norm)\n",
        "print(\"Number of PNEUMONIA - TRAIN :\", num_tr_pneu, \"\\n\")\n",
        "\n",
        "print(\"TOTAL NUMBER OF VALIDATION IMAGES:\", num_vl)\n",
        "print(\"Number of NORMAL    - VALIDATION :\", num_vl_norm)\n",
        "print(\"Number of PNEUMONIA - VALIDATION :\", num_vl_pneu, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zov7GRJ4b8o7"
      },
      "source": [
        "Let's now deal with the imbalance in the number of normal and pneumonia images in training set using class weights. This dictionary of class weights will be used later on. \n",
        "\n",
        "According to TF documentations, class weights \"can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\" (https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbIM4HvIlFMf"
      },
      "source": [
        "# Compute class weights for normal and pneumonia images\n",
        "weight_norm = (1 / NUM_NORM)*(NUM_TRAIN)/2.0 \n",
        "weight_pneu = (1 / NUM_PNEU)*(NUM_TRAIN)/2.0\n",
        "\n",
        "# Create a dictionary to store the weights\n",
        "class_weight = {0: weight_norm, 1: weight_pneu}\n",
        "\n",
        "print('Weight for NORMAL    (class 0): {:.2f}'.format(weight_norm))\n",
        "print('Weight for PNEUMONIA (class 1): {:.2f}'.format(weight_pneu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBN2J0FVB2mU"
      },
      "source": [
        "## 05. Data Augmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qJymR9kBK7u"
      },
      "source": [
        "We will be using a batch size of 130 and image size of 200x200. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmcn0lBVB7zN"
      },
      "source": [
        "BATCH_SIZE = 130\n",
        "IMG_SHAPE = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD_9CEY1ZUMW"
      },
      "source": [
        "Create a function that will display images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sNpZ1l6YstY"
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns \n",
        "# where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qWI6oL1YfTl"
      },
      "source": [
        "### Applying Horizontal Flip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT6-h3SoBZFl"
      },
      "source": [
        "We use ImageDataGenerator to rescale the images by 255 and then apply a random horizontal flip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GCEybaeCTlR"
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True, \n",
        "                                               target_size=(IMG_SHAPE,IMG_SHAPE))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mIaoS-zZC6H"
      },
      "source": [
        "### Applying Rotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APZIXGOaZIqo"
      },
      "source": [
        "We use ImageDataGenerator to rescale the images by 255 and then apply a random rotation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9OG_aUQCwb1"
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True, \n",
        "                                               target_size=(IMG_SHAPE,IMG_SHAPE))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPo1OKP-ZMch"
      },
      "source": [
        "### Applying Zoom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO8isKSBZQYw"
      },
      "source": [
        "We use ImageDataGenerator to rescale the images by 255 and then apply a random zoom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOgRw7SCDTwU"
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.25)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True, \n",
        "                                               target_size=(IMG_SHAPE,IMG_SHAPE))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkLk5eBHZpKk"
      },
      "source": [
        "### Combining the Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bRsBt8pFKut"
      },
      "source": [
        "Preparing data for training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adfqZBkDDw8s"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    zoom_range=0.25,\n",
        "    horizontal_flip=True, \n",
        ")\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True, \n",
        "                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "triM4fjeFT9c"
      },
      "source": [
        "Preparing data for validation images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrfrJel_FCQZ"
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                 directory=val_dir,\n",
        "                                                 target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhBfFaTgCf8C"
      },
      "source": [
        "Preparing data for testing images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZyiHK1eCh-8"
      },
      "source": [
        "image_gen_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_data_gen = image_gen_test.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                   directory=test_dir,\n",
        "                                                   target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                   class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF7NxdkBGFck"
      },
      "source": [
        "## 05. Creating a CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZsNxofDaKXl"
      },
      "source": [
        "The genereal structure is as follows:\n",
        "\n",
        "* Three pairs of convolution and max-pooling layers\n",
        "   - 16, 32, and 62 nodes in that order\n",
        "   - Same Padding\n",
        "   - ReLU Activation\n",
        "* Flatten\n",
        "* Two Dense layers\n",
        "    - 512 and 2 nodes in that order\n",
        "    - ReLU Activation for the first dense layer\n",
        "    - Dropout rate at 0.2 at each dense layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTfWvJz3G_f8"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE,3)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6aPbIf5HfxA"
      },
      "source": [
        "## 06. Compiling the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvvjvIQUHj96"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqnnqviYnKI7"
      },
      "source": [
        "callback_cp = tf.keras.callbacks.ModelCheckpoint(\"pneumonia_model.hdf5\",\n",
        "                                                 save_best_only=True)\n",
        "\n",
        "callback_es = tf.keras.callbacks.EarlyStopping(patience=10,\n",
        "                                               restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMkNN_ZTHrB7"
      },
      "source": [
        "## 07. Training the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzfXgJ2lIDWq"
      },
      "source": [
        "epochs = 40\n",
        "\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(train_data_gen.n / float(BATCH_SIZE))),\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(val_data_gen.n / float(BATCH_SIZE)))\n",
        "    # class_weight=class_weight,\n",
        "    # callbacks=[callback_cp, callback_es]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZMp3RsYbtKR"
      },
      "source": [
        "## 08. Visualizing Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lP7L9WxQ1Gn"
      },
      "source": [
        "# Accuracy\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# x-axis\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "# First figure: Model Accuracy\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "# Second figure: Model Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3az9rbTWNtDX"
      },
      "source": [
        "## 09. Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ8GvieXh9dZ"
      },
      "source": [
        "class_names = np.array(['Normal','Pneumonia'])\n",
        "\n",
        "image_batch, label_batch = next(iter(test_data_gen))\n",
        "\n",
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_batch = tf.squeeze(predicted_batch).numpy()\n",
        "\n",
        "predicted_ids = np.argmax(predicted_batch, axis=-1)\n",
        "predicted_class_names = class_names[predicted_ids]\n",
        "\n",
        "print(predicted_class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je3xkRc5i_cL"
      },
      "source": [
        "print(\"Labels:\\n\", label_batch.astype('int64'))\n",
        "print(\"Predicted labels:\\n\", predicted_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgrrz5Hijvkc"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.subplots_adjust(hspace=0.5)\n",
        "  plt.imshow(image_batch[n])\n",
        "\n",
        "  if predicted_ids[n] == label_batch[n]:\n",
        "    color = \"blue\" \n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  plt.title(predicted_class_names[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "\n",
        "_ = plt.suptitle(\"Model Predictions\\n (Blue: correct, Red: incorrect)\", \n",
        "                 fontsize='xx-large', fontweight='bold')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROtBvTDYMhMc"
      },
      "source": [
        "acc = model.evaluate(test_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}